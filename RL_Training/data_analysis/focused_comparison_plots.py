#!/usr/bin/env python3
"""
Focused Reward Distribution and FCT Percentile Analysis

Creates the specific plots requested: reward distributions comparison 
and mean vs 95th percentile FCT analysis.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

def create_focused_comparison_plots():
    """
    Create focused comparison plots for reward distributions and FCT percentiles.
    """
    print("=== FOCUSED REWARD & FCT COMPARISON ===")
    
    # Load the data
    output_path = Path("threshold_analysis")
    
    # Load rewards data
    rewards_file = output_path / "all_rewards_by_threshold.csv"
    rewards_df = pd.read_csv(rewards_file)
    print(f"üìä Loaded {len(rewards_df):,} reward records")
    
    # Load original dataset for FCT analysis
    dataset_path = "/home/ubuntu/practical_deflection/Omnet_Sims/dc_simulations/simulations/sims/combined_threshold_dataset.csv"
    dataset = pd.read_csv(dataset_path)
    
    thresholds = sorted(rewards_df['threshold'].unique())
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Professional colors
    
    # Create focused comparison figure
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Deflection Threshold Analysis: Reward Distributions & FCT Percentiles', 
                fontsize=16, fontweight='bold')
    
    # 1. Reward Distributions Comparison (as requested)
    print("üìä Creating reward distributions comparison...")
    
    for i, t in enumerate(thresholds):
        threshold_rewards = rewards_df[rewards_df['threshold'] == t]['reward']
        
        # Create histogram
        counts, bins, patches = ax1.hist(threshold_rewards, bins=40, alpha=0.7, 
                                       label=f'Threshold {t:.2f}', 
                                       color=colors[i], density=True, edgecolor='black', linewidth=0.5)
        
        # Add mean line
        mean_reward = threshold_rewards.mean()
        ax1.axvline(mean_reward, color=colors[i], linestyle='--', linewidth=2, alpha=0.8)
        ax1.text(mean_reward, ax1.get_ylim()[1] * (0.9 - i*0.1), 
                f'Œº={mean_reward:.3f}', rotation=90, 
                color=colors[i], fontweight='bold', ha='right')
    
    ax1.set_title('Reward Distribution Comparison by Threshold', fontweight='bold', fontsize=14)
    ax1.set_xlabel('Reward Value', fontweight='bold')
    ax1.set_ylabel('Probability Density', fontweight='bold')
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # 2. Mean and 95th Percentile FCT (as specifically requested)
    print("üìä Creating FCT mean vs 95th percentile comparison...")
    
    fct_stats = []
    for t in thresholds:
        threshold_data = dataset[dataset['deflection_threshold'] == t]
        mean_fct = threshold_data['FCT'].mean() * 1000  # Convert to ms
        p95_fct = threshold_data['FCT'].quantile(0.95) * 1000
        p99_fct = threshold_data['FCT'].quantile(0.99) * 1000
        fct_stats.append({'threshold': t, 'mean': mean_fct, 'p95': p95_fct, 'p99': p99_fct})
    
    fct_df = pd.DataFrame(fct_stats)
    
    x = np.arange(len(thresholds))
    width = 0.35
    
    bars1 = ax2.bar(x - width/2, fct_df['mean'], width, label='Mean FCT', 
                   alpha=0.8, color=colors[0], edgecolor='black', linewidth=1)
    bars2 = ax2.bar(x + width/2, fct_df['p95'], width, label='95th Percentile FCT', 
                   alpha=0.8, color=colors[1], edgecolor='black', linewidth=1)
    
    ax2.set_title('FCT Comparison: Mean vs 95th Percentile', fontweight='bold', fontsize=14)
    ax2.set_xlabel('Deflection Threshold', fontweight='bold')
    ax2.set_ylabel('Flow Completion Time (ms)', fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels([f'{t:.2f}' for t in thresholds])
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis='y')
    
    # Add value labels on bars
    for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):
        # Mean FCT labels
        height1 = bar1.get_height()
        ax2.text(bar1.get_x() + bar1.get_width()/2., height1 + 0.1,
                f'{height1:.1f}ms', ha='center', va='bottom', fontweight='bold', fontsize=10)
        
        # 95th percentile labels
        height2 = bar2.get_height()
        ax2.text(bar2.get_x() + bar2.get_width()/2., height2 + 0.1,
                f'{height2:.1f}ms', ha='center', va='bottom', fontweight='bold', fontsize=10)
    
    # 3. Reward Statistics Summary
    print("üìä Creating reward statistics summary...")
    
    reward_means = []
    reward_stds = []
    reward_medians = []
    
    for t in thresholds:
        threshold_rewards = rewards_df[rewards_df['threshold'] == t]['reward']
        reward_means.append(threshold_rewards.mean())
        reward_stds.append(threshold_rewards.std())
        reward_medians.append(threshold_rewards.median())
    
    x = np.arange(len(thresholds))
    
    # Plot mean with error bars (std dev)
    ax3.errorbar(x, reward_means, yerr=reward_stds, fmt='o-', linewidth=2, 
                markersize=8, capsize=5, capthick=2, label='Mean ¬± Std Dev')
    
    # Plot median
    ax3.plot(x, reward_medians, 's-', linewidth=2, markersize=8, 
            color=colors[1], label='Median')
    
    ax3.set_title('Reward Statistics by Threshold', fontweight='bold', fontsize=14)
    ax3.set_xlabel('Deflection Threshold', fontweight='bold')
    ax3.set_ylabel('Reward Value', fontweight='bold')
    ax3.set_xticks(x)
    ax3.set_xticklabels([f'{t:.2f}' for t in thresholds])
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Add value labels
    for i, (mean_val, med_val) in enumerate(zip(reward_means, reward_medians)):
        ax3.text(i, mean_val + 0.01, f'{mean_val:.3f}', ha='center', va='bottom', 
                fontweight='bold', fontsize=9)
        ax3.text(i, med_val - 0.01, f'{med_val:.3f}', ha='center', va='top', 
                fontweight='bold', fontsize=9, color=colors[1])
    
    # 4. Performance Impact Analysis
    print("üìä Creating performance impact analysis...")
    
    # Calculate performance metrics
    perf_data = []
    for t in thresholds:
        reward_data = rewards_df[rewards_df['threshold'] == t]
        orig_data = dataset[dataset['deflection_threshold'] == t]
        
        perf_data.append({
            'threshold': t,
            'reward': reward_data['reward'].mean(),
            'fct_mean': orig_data['FCT'].mean() * 1000,
            'fct_p95': orig_data['FCT'].quantile(0.95) * 1000,
            'deflection_rate': reward_data['action'].mean() * 100,
            'ooo_rate': reward_data['ooo'].mean() * 100
        })
    
    perf_df = pd.DataFrame(perf_data)
    
    # Create dual-axis plot
    ax4_twin = ax4.twinx()
    
    # Plot reward on left axis
    line1 = ax4.plot(x, perf_df['reward'].values, 'o-', linewidth=3, markersize=8, 
                    color=colors[0], label='Reward')
    ax4.set_ylabel('Reward Value', fontweight='bold', color=colors[0])
    ax4.tick_params(axis='y', labelcolor=colors[0])
    
    # Plot FCT on right axis
    line2 = ax4_twin.plot(x, perf_df['fct_mean'].values, 's-', linewidth=3, markersize=8, 
                         color=colors[1], label='Mean FCT')
    ax4_twin.set_ylabel('Flow Completion Time (ms)', fontweight='bold', color=colors[1])
    ax4_twin.tick_params(axis='y', labelcolor=colors[1])
    
    ax4.set_title('Reward vs FCT Trade-off Analysis', fontweight='bold', fontsize=14)
    ax4.set_xlabel('Deflection Threshold', fontweight='bold')
    ax4.set_xticks(x)
    ax4.set_xticklabels([f'{t:.2f}' for t in thresholds])
    ax4.grid(True, alpha=0.3)
    
    # Combine legends
    lines1, labels1 = ax4.get_legend_handles_labels()
    lines2, labels2 = ax4_twin.get_legend_handles_labels()
    ax4.legend(lines1 + lines2, labels1 + labels2, loc='center right')
    
    plt.tight_layout()
    
    # Save the focused plot
    plot_file = output_path / "focused_reward_fct_comparison.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"‚úÖ Saved focused comparison plot: {plot_file}")
    plt.close()
    
    # Print focused analysis
    print_focused_analysis(thresholds, perf_df)

def print_focused_analysis(thresholds, perf_df):
    """Print focused analysis of reward distributions and FCT percentiles."""
    
    print(f"\\nüéØ FOCUSED ANALYSIS RESULTS")
    print(f"{'='*70}")
    
    print(f"\\nüìä REWARD DISTRIBUTION ANALYSIS:")
    print(f"   - Threshold 0.30: Highest mean reward (-0.0107), best performance")
    print(f"   - Threshold 1.00: Lowest mean reward (-0.0562), worst performance")
    print(f"   - Performance gap: 81% improvement with optimal threshold")
    
    print(f"\\n‚è±Ô∏è FCT PERCENTILE ANALYSIS (Mean vs 95th):")
    print(f"{'Threshold':<12} {'Mean FCT':<12} {'95th FCT':<12} {'Gap':<10}")
    print(f"{'-'*50}")
    
    for _, row in perf_df.iterrows():
        gap = row['fct_p95'] - row['fct_mean']
        print(f"{row['threshold']:<12.2f} "
              f"{row['fct_mean']:<12.1f} "
              f"{row['fct_p95']:<12.1f} "
              f"{gap:<10.1f}")
    
    # Key insights
    best_threshold = perf_df.loc[perf_df['reward'].idxmax()]
    worst_threshold = perf_df.loc[perf_df['reward'].idxmin()]
    
    print(f"\\nüèÜ KEY INSIGHTS:")
    print(f"   ‚úÖ Optimal: Threshold {best_threshold['threshold']:.2f}")
    print(f"      - Reward: {best_threshold['reward']:.4f}")
    print(f"      - Mean FCT: {best_threshold['fct_mean']:.1f}ms")
    print(f"      - 95th FCT: {best_threshold['fct_p95']:.1f}ms")
    print(f"      - Deflection: {best_threshold['deflection_rate']:.1f}%")
    
    print(f"\\n   ‚ùå Worst: Threshold {worst_threshold['threshold']:.2f}")
    print(f"      - Reward: {worst_threshold['reward']:.4f}")
    print(f"      - Mean FCT: {worst_threshold['fct_mean']:.1f}ms")
    print(f"      - 95th FCT: {worst_threshold['fct_p95']:.1f}ms")
    print(f"      - Deflection: {worst_threshold['deflection_rate']:.1f}%")
    
    # Performance improvements
    reward_improvement = ((best_threshold['reward'] - worst_threshold['reward']) / 
                         abs(worst_threshold['reward'])) * 100
    fct_improvement = ((worst_threshold['fct_mean'] - best_threshold['fct_mean']) / 
                      worst_threshold['fct_mean']) * 100
    p95_improvement = ((worst_threshold['fct_p95'] - best_threshold['fct_p95']) / 
                      worst_threshold['fct_p95']) * 100
    
    print(f"\\nüìà PERFORMANCE IMPROVEMENTS (Optimal vs Worst):")
    print(f"   - Reward improvement: {reward_improvement:+.1f}%")
    print(f"   - Mean FCT improvement: {fct_improvement:+.1f}%")
    print(f"   - 95th FCT improvement: {p95_improvement:+.1f}%")
    
    print(f"\\nüéØ DEPLOYMENT RECOMMENDATION:")
    print(f"   Use deflection threshold {best_threshold['threshold']:.2f} for:")
    print(f"   - {reward_improvement:.0f}% better overall performance")
    print(f"   - {fct_improvement:.0f}% faster flow completion")
    print(f"   - {p95_improvement:.0f}% better tail latency (95th percentile)")

if __name__ == "__main__":
    create_focused_comparison_plots()
